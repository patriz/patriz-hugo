+++
date          = "2018-11-05T02:37:00+00:00"
draft         = true
title         = "[번역] Introduction to modern network load balancing and proxying"
tags          = ["Microservice", "Load Balancing", "DevOps"]
categories    = ["DevOps"]
slug          = "modern-network-load-balancing-and-proxying"
notoc         = true
socialsharing = true
nocomment     = false
+++

# 현대적인 네트워크 로드 밸런싱 및 프록시 소개

최근 네트워크 로드 밸런싱과 프락시에 관한 입문 교육 자료가 부족하다는 사실이 관심을 끌었습니다. 어떻게 이게 가능하지? 라고 속으로 생각해보았습니다.  로드 밸런싱은 안정적인 분산 시스템 구축에 필요한 핵심 개념 중 하나입니다. 당연히 쓸만한 고급진 정보들이 있어야 하겠지. 검색해보고 고를만한 것들이 사실 별로 없다는 것을 알게 되었습니다. 위키피디아 기사에는 일부 개념에 대한 개요가 포함되어 있긴 하나, 유연한 처리 방법들은 아니었습니다. 특히, 현대적인 마이크로 서비스 아키텍처에 관해서 말이죠. 로드 밸런싱을 대한 구글 검색은 주로 버즈 워드가 많고 내용은 없는 공급 업체 페이지들입니다.  

이 글에서 저는 현대적인 네트워크 로드밸런싱과 프락시를 소개하며 정보 부족을 해결하려고 합니다. 이것은, 솔직히 말해서, 전체 책의 주제가 될 수 있는 방대한 주제입니다. 이 기사의 블로그 길이를 유념하면서 복잡한 주제 세트들을 간단한 개요로 추출하려고 합니다. 관심과 피드백에 따라 추후 개별 주제에 대한 자세한 후속 게시물을 고려할 것입니다. 

특이하고 이상한 이 글을 왜 썼는지에 대한 약간의 배경으로 - 시작합니다!

## 네트워크 로드 밸런싱과 프락싱이 무엇인가요?

위키피디아는 다음과 같이 로드밸런싱을 정의합니다:

> 컴퓨팅에서 로드 밸런싱은 컴퓨터, 컴퓨터 클러스터, 네트워크 링크, 중앙 처리 장치 또는 디스크 드라이브와 같은 여러 컴퓨팅 리소스에서 작업 부하 분산을 향상시킵니다. 로드 밸런싱은 리소스 사용을 최적화하고 처리량을 극대화하며 응답 시간을 최소화하고 단일 리소스의 오버로드를 방지하는 것을 목표로 합니다. 단일 구성 요소 대신 로드 밸런싱과 함께 여러 구성 요소를 사용하면 이중화를 통해 안정성과 가용성을 높일 수 있습니다. 로드 균형 조정에는 보통 멀티 레이어 스위치 또는 도메인 이름 시스템 서버 프로세스와 같은 전용 소프트웨어 또는 하드웨어가 사용됩니다.

위의 정의는 네트워크뿐만 아니라 컴퓨팅의 모든 측면에 적용됩니다. 운영 체제는 로드 밸런싱을 사용하여 물리적 프로세서 간에 작업을 스케줄링하고, Kubernetes과 같은 컨테이너 오케스트레이터는 로드 밸런싱을 사용하여 컴퓨팅 클러스터 전체에서 작업을 스케줄링하고, 네트워크 로드 밸런서는 사용 가능한 백엔드에서 네트워크 작업을 스케줄링합니다. 이 게시물의 나머지 부분에서는 네트워크 로드 밸런싱만 다룹니다.

<img src="https://cdn-images-1.medium.com/max/1600/1*cCV-7Q-DDw87xNnTIVIhEg.png">
<small><center>그림 1. 네트워크 로드 밸런싱 개요</center></small>


그림 1은 네트워크 로드 밸런싱의 개략적인 개요를 보여줍니다. 일부 클라이언트는 일부 백엔드에 리소스를 요청하고 있습니다. 로드 밸런서는 클라이언트와 백엔드 사이에 위치하며 높은 수준에서 몇 가지 중요한 작업을 수행합니다.

- **서비스 검색**: 시스템에서 사용할 수 있는 백엔드는 무엇입니까? 그들 주소가 어떻게 됩니까?
- **헬스 체킹**: 현재 정상이며 요청을 수락할 수 있는 백엔드는 무엇입니까?
- **로드 밸런싱**: 모든 정상적인 백엔드에 대한 개별 요청의 균형을 맞추기 위해 어떤 알고리즘을 사용해야 합니까?

분산 시스템에서 로드 밸런싱을 적절하게 사용하면 다음과 같은 몇 가지 이점이 있습니다.

- **네이밍 추상화**: 모든 백엔드(서비스 검색)에 대해 알아야 하는 모든 클라이언트 대신, 클라이언트는 미리 정의된 메커니즘을 통해 로드 밸런서를 처리하고 이름 확인 (Name resolution) 작업을 로드 밸런서에 위임할 수 있습니다. 미리 정의된 메커니즘은 기본 제공 라이브러리 및 잘 알려진 DNS/IP/포트 위치를 포함하며 아래에서 보다 자세히 설명합니다.

- **내결함성**: 상태 확인 및 다양한 알고리즘 기술을 통해 로드 밸런서는 불량 또는 과부하가 걸린 백엔드를 효과적으로 라우팅할 수 있습니다. 이는 운영자가 전형적인 여가 시간 대비 비상 조치로 불량 백엔드를 수정할 수 있다는 것을 뜻합니다.

- **비용 및 성능 이점**: 분산 시스템 네트워크는 거의 동질적인 집단이 아닙니다. 시스템이 여러 네트워크 Zone과 Region에 걸쳐 있을 가능성이 높습니다. Zone 내에서, 네트워크는 종종 상대적으로 신청량이 낮은 방법으로 구축됩니다. Zone 간에 과다 신청이 표준이 됩니다. 지능형 로드 밸런싱을 통해 가능한 많은 Zone 내에서 요청 트래픽을 유지할 수 있으므로 성능 (대기 시간 감소)이 향상되고 전체 시스템 비용이 절감됩니다 (Zone간 대역폭 및 광섬유 필요 감소).

### 로드 밸런서 대 프록시

네트워크 로드 밸런싱 장치에 대해 이야기할 때, 로드 밸런싱 장치 및 프록시라는 용어는 업계 내에서 대략적으로 서로 바꿔 사용할 수 있습니다. 이 게시물은 또한 용어들을 일반적으로 동등한 것으로 취급합니다. (현학적으로, 모든 프록시가 로드 밸런서는 아니지만 대다수의 프록시는 로드 밸런싱을 기본 기능으로 수행합니다.)

일부에서는 내장형 클라이언트 라이브러리의 일부로 로드 밸런싱을 수행하면 로드 밸런서가 실제로 프록시가 아니라고 추가적으로 주장할 수 있습니다. 그러나, 저는 구별이 이미 혼란스러운 주제에 불필요한 복잡성을 더한다고 입증합니다. 로드 밸런서 토폴로지의 유형은 아래에서 자세히 설명되지만, 이 게시물에서는 내장형 로드 밸런서 토폴로지를 프록시 방식의 특수한 경우로 취급히는데 이 때 애플리케이션은 로드 밸런서와 동일한 추상화를 모두 제공하는 내장된 라이브러리를 통해 프록시합니다.

### L4 (연결/세션) 로드 밸런싱

오늘날 업계 전반에서 로드 밸런싱을 논의할 때 솔루션은 종종 L4와 L7의 두 가지 범주로 분류됩니다. 이러한 범주는 OSI 모델의 4계층과 7계층을 참조합니다. L7 로드 밸런싱에 대해 논의할 때 명확해질 수 있는 이유 때문에, 이것이 우리가 사용하는 용어라는 것은 유감스러운 일이라고 생각합니다. OSI 모델은 TCP 및 UDP와 같은 기존 레이어 4 프로토콜을 포함하지만 종종 다양한 OSI 계층의 이런저런 잡동사니 프로토콜(예, 만약 L4 TCP 로드 밸런서도 TLS을 지원한다면, 이제 L7 로드 밸런서가 되는 건가요?)을 포함하기 일쑤인지라 로드 밸런싱 솔루션의 복잡성에 대한 매우 낮은 근사치입니다.

### L7 (어플리케이션) 로드 밸런싱

### L7 로드 밸런싱 그리고 OSI 모델