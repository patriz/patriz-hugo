+++
date          = "2018-11-05T02:37:00+00:00"
draft         = true
title         = "[번역] 최신 네트워크 로드 밸런싱 및 프록시 소개"
tags          = ["Microservice", "Load Balancing", "DevOps"]
categories    = ["DevOps"]
slug          = "modern-network-load-balancing-and-proxying"
notoc         = true
socialsharing = true
nocomment     = false
+++

# 최신 네트워크 로드 밸런싱 및 프록시 소개

최근 네트워크 로드 밸런싱과 프록시에 관한 입문 교육 자료가 부족하다는 사실이 관심을 끌었습니다. 어떻게 이게 가능하지? 라고 속으로 생각했습니다. 로드 밸런싱은 안정적인 분산 시스템 구축에 필요한 핵심 개념 중 하나입니다. 당연히 쓸만한 고급진 정보들이 있어야 합니다. 검색을 해보았으나 사실 쓸만한 것들이 별로 없다는 것을 알게 되었습니다. 위키피디아 기사에는 일부 개념에 대한 개요가 포함되어 있긴 하나, 우아한 내용들은 아니었습니다. 특히, 최신 마이크로 서비스 아키텍처에 관해서 말이죠. 로드 밸런싱을 대한 구글 검색은 주로 버즈 워드가 많고 내용은 없는 업체 페이지들입니다.  

이 글에서 저는 최신 네트워크 로드밸런싱과 프록시를 소개하며 정보 부족을 해결하려고 합니다. 이것은, 솔직히 말해서, 책 한 권 전체의 주제가 될 수 있는 방대한 주제입니다. 이 기사의 블로그 길이를 유념하면서 복잡한 주제 세트를 간단한 개요로 뽑아보려고 합니다. 관심과 피드백에 따라 추후 개별 주제에 대한 자세한 후속 게시물을 고려할 것입니다. 

특이하고 이상한 이 글을 왜 썼는지에 대한 약간의 배경과 함께 - 시작하겠습니다!

## 네트워크 로드 밸런싱과 프락싱이 무엇인가요?

위키피디아는 다음과 같이 로드밸런싱을 정의합니다:

> 컴퓨팅에서 로드 밸런싱은 컴퓨터, 컴퓨터 클러스터, 네트워크 링크, 중앙 처리 장치 또는 디스크 드라이브와 같은 여러 컴퓨팅 리소스에서 작업 부하 분산을 향상시킵니다. 로드 밸런싱은 리소스 사용을 최적화하고 처리량을 극대화하며 응답 시간을 최소화하고 단일 리소스의 오버로드를 방지하는 것을 목표로 합니다. 단일 구성 요소 대신 로드 밸런싱과 함께 여러 구성 요소를 사용하면 이중화를 통해 안정성과 가용성을 높일 수 있습니다. 로드 밸런싱은 보통 멀티 레이어 스위치 또는 도메인 이름 시스템 서버 프로세스와 같은 전용 소프트웨어 또는 하드웨어가 사용됩니다.

위의 정의는 네트워크뿐만 아니라 컴퓨팅의 모든 측면에 적용됩니다. 운영 체제는 로드 밸런싱을 사용하여 물리적 프로세서 간에 작업을 스케줄링하고, Kubernetes과 같은 컨테이너 오케스트레이터는 로드 밸런싱을 사용하여 컴퓨팅 클러스터 전체에서 작업을 스케줄링하고, 네트워크 로드 밸런서는 사용 가능한 백엔드에서 네트워크 작업을 스케줄링합니다. 이 게시물의 나머지 부분에서는 네트워크 로드 밸런싱만 다룹니다.

<img src="https://cdn-images-1.medium.com/max/1600/1*cCV-7Q-DDw87xNnTIVIhEg.png"/>
<small><center>그림 1. 네트워크 로드 밸런싱 개요</center></small>


그림 1은 네트워크 로드 밸런싱의 개략적인 개요를 보여줍니다. 일부 클라이언트는 일부 백엔드에 리소스를 요청하고 있습니다. 로드 밸런서는 클라이언트와 백엔드 사이에 위치하며 상위 레벨에서 몇 가지 중요한 작업을 수행합니다.

- **서비스 검색**: 시스템에서 사용할 수 있는 백엔드는 무엇입니까? 그들 주소가 어떻게 됩니까?
- **헬스 체킹**: 현재 정상이며 요청을 수락할 수 있는 백엔드는 무엇입니까?
- **로드 밸런싱**: 모든 정상적인 백엔드에 대한 개별 요청의 균형을 맞추기 위해 어떤 알고리즘을 사용해야 합니까?

분산 시스템에서 로드 밸런싱을 적절하게 사용하면 다음과 같은 몇 가지 이점이 있습니다.

- **네이밍 추상화**: 모든 백엔드(서비스 검색)에 대해 알아야 하는 모든 클라이언트 대신, 클라이언트는 미리 정의된 메커니즘을 통해 로드 밸런서를 처리하고 이름 확인(Name resolution) 작업을 로드 밸런서에 위임할 수 있습니다. 미리 정의된 메커니즘은 기본 제공 라이브러리 및 잘 알려진 DNS/IP/포트 위치를 포함하며 아래에서 보다 자세히 설명합니다.

- **내결함성**: 상태 확인 및 다양한 알고리즘 기술을 통해 로드 밸런서는 불량 또는 과부하가 걸린 백엔드를 효과적으로 라우팅할 수 있습니다. 이는 운영자가 전형적인 여가 시간 대비 비상 조치로 불량 백엔드를 수정할 수 있다는 것을 뜻합니다.

- **비용 및 성능 이점**: 분산 시스템 네트워크는 거의 동질적인 집단으로 구성되지 않습니다. 시스템은 여러 네트워크 Zone과 Region에 걸쳐 있을 가능성이 높습니다. Zone 내에서, 네트워크는 종종 상대적으로 요청량이 낮은 방법으로 구축됩니다. Zone 간에 과다 요청이 표준이 됩니다. 지능형 로드 밸런싱을 통해 가능한 많은 Zone 내에서 요청 트래픽을 유지할 수 있으므로 성능 (대기 시간 감소)이 향상되고 전체 시스템 비용이 절감됩니다 (Zone간 대역폭 및 광섬유 필요 감소).

### 로드 밸런서 대 프록시

네트워크 로드 밸런싱 장치에 대해 이야기할 때, 로드 밸런싱 장치 및 프록시라는 용어는 업계 내에서 대략적으로 서로 혼용할 수 있습니다. 이 포스트 또한 용어들을 일반적으로 동등한 것으로 취급합니다. (엄밀히 따지면, 모든 프록시가 로드 밸런서는 아니지만 대다수의 프록시는 로드 밸런싱이 기본적인 기능입니다.)

일부에서는 내장형 클라이언트 라이브러리의 부분으로 로드 밸런싱을 수행하면 로드 밸런서가 실제로 프록시가 아니라고 덧붙이며 주장할 수 있습니다. 그러나, 저는 구별이 이미 혼란스러운 주제에 불필요한 복잡성을 더하는 것이라고 반박합니다. 로드 밸런서 토폴로지의 유형은 아래에서 자세히 설명되지만, 이 포스트에서는 내장형 로드 밸런서 토폴로지를 프록시 방식의 특수한 경우로 취급하는데 이 때 애플리케이션은 로드 밸런서와 동일한 추상화를 모두 제공하는 내장된 라이브러리를 통해 프록시합니다.

### L4 (연결/세션) 로드 밸런싱

오늘날 업계 전반에서 로드 밸런싱을 논의할 때 솔루션은 종종 L4와 L7의 두 가지 범주로 분류됩니다. 이러한 범주는 OSI 모델의 4계층과 7계층을 참조합니다. L7 로드 밸런싱에 대해 논의할 때 명확해질 수 있는 이유 때문에, 이것이 우리가 사용하는 용어라는 것은 유감스러운 일이라고 생각합니다. OSI 모델은 TCP 및 UDP와 같은 기존 4계층 프로토콜을 포함하지만 종종 다양한 OSI 계층의 이런저런 잡동사니 프로토콜(예, 만약 L4 TCP 로드 밸런서가 마찬가지로 TLS을 지원하게 되면, 이제 L7 로드 밸런서가 되는 건가요?)을 포함하기 일쑤인지라 로드 밸런싱 솔루션의 복잡성에 대한 매우 낮은 근사치입니다.

<img src="https://cdn-images-1.medium.com/max/1600/1*1PjTpM3hLnm3iEAd4-_AaQ.png"/>
<small><center>그림 2. TCP L4 종료 로드 밸런싱</center></small>

그림 2는 기존 L4 TCP 로드 밸런서를 보여줍니다. 이 경우 클라이언트는 로드 밸런서에 TCP를 연결합니다. 로드 밸런서는 연결을 종료하고(즉, SYN에 직접 응답하고 백엔드를 선택한 다음 새 TCP 연결을 만듭니다(즉, 새 SYN 전송). 다이어그램의 세부 정보는 중요하지 않으며 아래 L4 로드 밸런싱 할애된 섹션에서 자세히 논의하겠습니다.

이 섹션의 핵심 사항은 L4 로드 밸런서가 일반적으로 L4 TCP/UDP 연결/세션 수준에서만 작동한다는 것입니다. 따라서 로드 밸런서는 바이트 앞뒤를 거칠게 셔플해서, 동일한 세션의 바이트가 동일한 백엔드에서 끝나도록 합니다. L4 로드 밸런서는 셔플링 중인 바이트의 애플리케이션 세부 정보를 인식하지 못합니다. 바이트는 HTTP, Redis, MongoDB 또는 다른 애플리케이션 프로토콜일 수 있습니다.

### L7 (어플리케이션) 로드 밸런싱

L4 로드 밸런싱은 간단하면서도 널리 사용됩니다. L7 (애플리케이션) 로드 밸런싱 투자를 보증하는 L4 로드 밸런싱의 단점은 무엇일까요? 다음 L4 관련 사례를 예로 들어 보겠습니다.

- 두 개의 gRPC/HTTP2 클라이언트는 백엔드와 통신하며 L4 로드 밸런서를 통해 연결하려고 합니다.
- L4 로드 밸런서는 들어오는 각 TCP 연결에 대해 단일 송신 TCP 연결을 생성하므로 두 개의 수신 연결과 두 개의 송신 연결이 발생합니다.
- 그런데, 클라이언트 A는 연결을 통해 분당 1개의 요청(RPM)을 보내고 클라이언트 B는 연결을 통해 초당 50개의 요청(RPS)을 보냅니다.

이전 시나리오에서 클라이언트 A를 처리하기 위해 선택된 백엔드는 클라이언트 B를 처리하기 위해 선택된 백엔드에 비해 약 3,000배의 부하를 처리합니다! 이것은 큰 문제이며, 일반적으로 시작부터 로드 밸런싱의 목적을 무산시킵니다. 또한 이 문제는 모든 멀티플렉싱, keep-alive 프로토콜에서 발생합니다. (멀티플렉싱은 단일 L4 연결을 통해 동시 응용 프로그램 요청을 보내고 사용 중인 요청이 없을 때 연결을 닫지 않는 것을 의미합니다.) 현대적인 프로토콜은 모두 효율성 이유(특히 TLS를 사용하여 연결을 암호화하는 경우)로 멀티플렉싱와 keep-alive 두 가지로 진화하고 있으므로 L4 로드 밸런서임 임피던스 불일치가 시간이 지남에 따라 더욱 뚜렷해지고 있습니다. L7 로드 밸런서가 이 문제를 해결합니다.

<img src="https://cdn-images-1.medium.com/max/1600/1*zsaxjSziEm1Tipr6kxs5Zg.png"/>
<small><center>그림 3. HTTP/2 L7 종료 로드 밸런싱</center></small>

그림 3은 L7 HTTP/2 로드 밸런서를 보여줍니다. 이 경우 클라이언트는 로드 밸런서에 단일 HTTP/2 TCP를 연결합니다. 그런 다음 로드 밸런서는 두 개의 백엔드 연결을 만듭니다. 클라이언트가 두 개의 HTTP/2 스트림을 로드 밸런서에 전송하면 스트림 1은 백엔드 1로 전송되고 스트림 2는 백엔드 2로 전송됩니다. 따라서 요청 부하가 매우 다른 멀티플렉싱 클라이언트도 백엔드에서 효율적으로 균형을 맞출 것입니다. 이것이 바로 L7 로드 밸런싱이 현대적 프로토콜에 매우 중요한 이유입니다.

### L7 로드 밸런싱 그리고 OSI 모델

앞서 L4 로드 밸런싱 섹션에서 말씀드린 것처럼 로드 밸런싱 기능을 설명하기 위해 OSI 모델을 사용하는 것은 문제가 있습니다. 그 이유는, 다른 것은 몰라도 OSI 모델에서 기술되는 것과 같이, L7 자체가 로드 밸런싱 추상화의 여러 개별 계층을 포괄하기 때문입니다. 예를 들어 HTTP 트래픽의 경우 다음과 같은 하위 계층을 생각해볼 수 있습니다.

- 선택적 TLS(Transport Layer Security). 네트워크쪽 사람들이 어떤 OSI 계층이 TLS에 속하는지 논의 중입니다. 이 논의를 위해 우리는 TLS L7을 검토할 것입니다.
- 물리적 HTTP 프로토콜(HTTP/1 또는 HTTP/2).
- 논리적 HTTP 프로토콜(헤더, 본문 데이터 및 트레일러).
- 메시징 프로토콜(gRPC, REST 등).

정교한 L7 로드 밸런싱 장치는 위의 각 하위 계층과 관련된 기능을 제공할 수 있습니다. 다른 L7 로드 밸런서에는 L7 범주에 속하는 기능 중 작은 부분만 있을 수 있습니다. 즉, L7 로드 밸런서 환경은 L4 범주보다 기능을 비교하는 관점에서 훨씬 더 복잡합니다. (물론 이 섹션에서는 HTTP에 대해 좀전에 다루었습니다. Redis, Kafka, MongoDB 등은 모두 L7 로드 밸런싱의 이점을 제공하는 L7 애플리케이션 프로토콜의 예입니다.)

## 로드 밸런서 기능들

이 섹션에서는 로드 밸런서가 제공하는 상위 레벨 기능들을 간략하게 요약합니다. 모든 로드 밸런서가 모든 기능을 제공하는 것은 아닙니다.

### 서비스 디스커버리 (Service discovery)

서비스 디스커버리는 로드 밸런서가 사용 가능한 백엔드의 집합을 결정하는 프로세스입니다. 방법은 매우 다양하며 다음과 같은 예를 들 수 있습니다.

- 정적 구성 파일.
- DNS
- Zookeeper, Etcd, Conceul 등
- Envoy의 범용 데이터 평면 API.

### 헬스 체크 (Health checking)

헬스 체크는 로드 밸런서가 트래픽을 처리하는데 백엔드를 사용할 수 있는지 여부를 결정하는 프로세스입니다. 헬스 체크는 일반적으로 두 가지 범주로 나뉩니다.

- **활성**: 로드 밸런서가 주기적인 간격(예: HTTP 요청을 `/healthcheck` 엔드포인트에 전송)을 통해 상태를 측정합니다.
- **수동**: 로드 밸런서가 주 데이터 흐름에서 상태를 감지합니다. 예를 들어, L4 로드 밸런서는 연속 3개의 연결 오류가 있는 경우 백엔드가 비정상이라고 결정할 수 있습니다. L7 로드 밸런서는 연속 세 개의 HTTP 503 응답 코드가 있는 경우 백엔드가 비정상이라고 결정할 수 있습니다.

### 부하 분산 (Load balancing)

그렇죠. 로드 밸런서는 실제로 부하 분산을 유지해야 합니다! 정상적인 백엔드 셋이 주어질 때, 연결이나 요청에 적합한 백엔드는 어떻게 선택될까요? 로드 밸런싱 알고리즘은 활발한 리서치 영역이며 랜덤 선택 및 라운드 로빈과 같은 단순한 영역에서 다양한 레이턴시 및 백엔드 부하를 계산하는 보다 복잡한 알고리즘에 이르기까지 다양합니다. 성능과 단순성을 고려할 때 가장 널리 사용되는 로드 밸런싱 알고리즘 중 하나는 [두 가지 최소 요청 로드 밸런싱의 힘](https://brooker.co.za/blog/2012/01/17/two-random.html)으로 알려져 있습니다. (역자 주, 링크 제목은 '두 가지 무작위 선택의 힘')

### 고정 세션 (Sticky sessions)

특정 애플리케이션에서는 같은 세션에 의한 요청이 같은 백엔드에 도달하는 것이 중요합니다. 이는 캐싱, 일시적인 복합 구성 상태 등과 관련이 있을 수 있습니다. 세션의 정의는 다양하며 HTTP 쿠키, 클라이언트 연결 속성 또는 기타 속성을 포함할 수 있습니다. 많은 L7 로드 밸런서는 고정 세션을 지원합니다. 한편, 세션의 고착도는 본질적으로 취약하기 때문에 세션에 의존하는 시스템을 설계할 때는 주의해야 합니다.

### TLS 종료 (TLS termination)

TLS 주제와 엣지 서비스 및 서비스와 서비스 간의 통신 보안 모두에서 TLS의 역할은 따로 포스트할 만큼의 가치가 있습니다. 이에 따라 많은 L7 로드 밸런서는 종료, 인증서 확인 및 핀닝, SNI를 사용한 인증서 서비스 등을 포함한 대량의 TLS 작업을 처리합니다.

### 관측성 (Observability)

말씀드린 대로, "관측성, 관측성, 관측성"이다. 네트워크는 본질적으로 신뢰할 수 없으며, 로드 밸런서는 종종 작업자가 문제를 해결할 수 있도록 무엇이 잘못되었는지 파악하는 데 도움이 되는 통계, 추적 및 로그를 내보낼 책임이 있습니다. 로드 밸런서는 관측 가능 출력에 따라 크게 다릅니다. 가장 진보된 로드 밸런싱 장치는 숫자 통계, 분산 추적 및 사용자 지정 가능한 로깅을 포함하는 많은 출력을 제공합니다. 향상된 관측성은 공짜가 아니라고 지적하고 싶습니다. 왜냐하면, 로드 밸런서는 이를 생성하기 위한 추가적인 일을 해야하기 때문입니다. 그러나 이들 데이터가 주는 이점은 상대적으로 성능이 약해서 생기는 결과보다 훨씬 큽니다.

### 보안 및 Dos 완화 (Security and DoS mitigation)

특히 엣지 배포를 위한 토폴로지(아래 참조)에서는 로드 밸런서가 속도 제한, 인증 및 DoS 완화(예: IP 주소 태깅 및 판독, 타피팅(tarpitting) 등)를 비롯한 다양한 보안 기능을 구현하는 경우가 많습니다.

### 설정 및 제어 플레인 (Configuration and control plane)

로드 밸런서는 설정될 필요가 있습니다. 대규모 배포에서 이는 상당한 작업이 될 수 있습니다. 일반적으로, 로드 밸런서를 구성하는 시스템은 "제어 플레인(control plane)"으로 알려져 있으며 구현이 매우 다양합니다. 이 항목에 대한 자세한 내용은 [데이터 플레인 대 제어 플레인 서비스 메쉬](https://medium.com/@mattklein123/service-mesh-data-plane-vs-control-plane-2774e720f7fc)에 대한 저의 포스트를 참조하세요.

### 그 외 정말 다양한 기능들 (And a whole lot more)

이 섹션에서는 로드 밸런서가 제공하는 기능들의 유형을 수박 겉핥기 식으로 다루어 보았습니다. 아래의 L7 로드 밸런서 섹션에서 추가적인 논의를 확인할 수 있습니다.

## 로드 밸런서 토폴로지 종류

이제 로드 밸런서가 무엇인지, L4와 L7 로드 밸런서의 차이와 로드 밸런서 기능의 요약에 대해 개괄적으로 살펴보았으므로 로드 밸런서가 적용된 다양한 분산 시스템 토폴로지로 이동할 것입니다. (다음 토폴로지 중 각 항목은 L4 및 L7 로드 밸런서에 모두 적용됩니다.)

### 미들 프록시

<img src="https://cdn-images-1.medium.com/max/1600/1*cCV-7Q-DDw87xNnTIVIhEg.png"/>
<small><center>그림 4. 미들 프록시 로드 밸런싱 토폴로지</center></small>

그림 4에 표시된 미들 프록시 토폴로지는 대부분의 독자들이 로드 밸런싱을 확보하는 가장 익숙한 방법입니다. 이 범주에는 Cisco, Juniper, F5 등의 하드웨어 장치, Amazon의 [ALB 및 NLB](https://aws.amazon.com/elasticloadbalancing/)와 Google의 [클라우드 로드 밸런서](https://cloud.google.com/load-balancing/) 같은 클라우드 소프트웨어 솔루션 및 [HAProxy](https://www.haproxy.com/), [NGINX](https://www.nginx.com/), 그리고 [Envoy](https://www.envoyproxy.io/)와 같은 순수 소프트웨어 자체 호스팅 솔루션이 포함됩니다. 미들 프록시 솔루션의 핵심은 사용자 단순성입니다. 일반적으로 사용자는 DNS를 통해 로드 밸런서에 연결되므로 다른 어떤 것도 걱정할 필요가 없습니다. 미들 프록시 솔루션의 핵심은 프록시(클러스터된 경우에도)가 단일 장애 지점이며 병목 현상도 증가한다는 점입니다. 미들 프록시도 운영을 어렵게 만드는 블랙박스입니다. 클라이언트에서 관측된 문제가 있습니까? 물리적 네트워크에서요? 중간 프록시에서요? 백엔드에서? 매우 알기 어려울 수 있습니다.

### 엣지 프록시

<img src="https://cdn-images-1.medium.com/max/1600/1*4zSWjsKnaC6QQmJ7PTj7Eg.png"/>
<small><center>그림 5. 엣지 프록시 로드 밸런싱 토폴로지</center></small>

그림 5에 표시된 엣지 프록시 토폴로지는 실제로 인터넷을 통해 로드 밸런서에 액세스할 수 있는 미들 프록시 토폴로지의 변형일 뿐입니다. 이 시나리오에서는 일반적으로 로드 밸런서가 TLS 종료, 속도 제한, 인증 및 정교한 트래픽 라우팅과 같은 추가 "API 게이트웨이" 기능을 제공해야 합니다. 엣지 프록시의 장단점은 미들 프록시와 같습니다. 일반적으로 인터넷을 지향하는 대규모 분산 시스템에서 전용 엣지 프록시를 배포할 수 없다는 것이 주의 사항입니다. 클라이언트는 일반적으로 서비스 소유자가 제어하지 않는 임의의 네트워크 라이브러리를 사용하여 DNS를 통해 시스템에 액세스해야 합니다(다음 섹션에서 설명하는 내장형 클라이언트 라이브러리 또는 사이드카 프록시 토폴로지는 클라이언트에서 직접 실행하기에는 실용적이지 않습니다). 추가적으로, 보안상의 이유로 모든 인터넷 트래픽이 시스템에 들어오는 수단으로 단일 게이트웨이를 사용하는 것이 좋습니다.

### 내장형 클라이언트 라이브러리

<img src="https://cdn-images-1.medium.com/max/1600/1*nuqZiYoFEkDe2cUgMh0aQw.png"/>
<small><center>그림 6. 내장형 클라이언트 라이브러리를 통한 로드 밸런싱</center></small>

미들 프록시 토폴로지에 내재된 단일 장애 지점과 확장 문제를 피하기 위해, 보다 정교한 인프라는 그림 6에서 보는 것처럼 라이브러리를 통해 로드 밸런서를 서비스에 직접 내장하는 쪽으로 이동했으며, 대부분의 라이브러리들은 다양한 기능을 지원하고 있습니다. [Finagle](https://twitter.github.io/finagle/), [Eureka/Ribbon/Hystrix](https://netflix.github.io/) 및 [gRPC](https://grpc.io/)(Stougy라고 하는 내부 Google 시스템을 기반으로 함) 라이브러리 기반 솔루션의 주요 장점은 로드 밸런서의 모든 기능을 각 클라이언트에 완전히 분산하여 단일 장애 지점과 앞서 설명한 확장성 이슈를 제거한다는 것입니다. 라이브러리 기반 솔루션의 주된 단점은 라이브러리가 조직에서 사용하는 모든 언어로 구현되어야 한다는 점입니다. 분산형 아키텍처는 점점 더 "폴리글랏(다중 언어)"이 증가하고 있습니다. 이러한 환경에서는 여러 언어로 매우 정교한 네트워킹 라이브러리를 다시 구축하는 비용이 엄청나게 들 수 있습니다. 마지막으로, 대규모 서비스 아키텍처에 걸쳐 라이브러리 업그레이드를 배포하는 것은 매우 고통스러울 수 있으며, 다양한 버전의 라이브러리가 동시에 운영 환경에서 실행되게 함으로써 운영 인지 부하(operational cognitive load)가 증가할 가능성이 매우 높습니다.

모두 그렇다고 해도, 위에서 언급한 라이브러리들은 프로그래밍 언어의 급증을 제한하고 라이브러리 업그레이드 고통을 극복한 회사들에게 있어 성공적이었습니다. 

### 사이드카 프록시

<img src="https://cdn-images-1.medium.com/max/1600/1*wPoZoz6cKAo0HBi1wmNZtA.png"/>
<small><center>그림 7. 사이드카를 통한 로드 밸런싱</center></small>

내장형 클라이언트 라이브러리 로드 밸런서 토폴로지의 변형은 그림 7에 표시된 사이드카 프록시 토폴로지입니다. 최근 몇 년간 이 토폴로지는 "서비스 메시"로 대중화되었습니다. 사이드카 프록시 이면의 아이디어는 다른 프로세스에 뛰어들어 약간의 지연 시간 페널티를 지불하는 비용으로 내장된 라이브러리 접근 방식의 모든 장점을 프로그래밍 언어를 락하지 않아도 얻을 수 있다는 것입니다. 이 글을 작성할 때, 가장 인기 있는 사이드카 프록시 로드 밸런서는 [Envoy](https://www.envoyproxy.io/), [NGINX](https://www.nginx.com/), [HAProxy](https://www.haproxy.com/) 및 [Linkerd](https://linkerd.io/)입니다. 사이드카 프록시 접근 방식에 대한 보다 자세한 처리는 [Envoy를 소개하는 블로그 포스트](https://eng.lyft.com/announcing-envoy-c-l7-proxy-and-communication-bus-92520b6c8191)와 또한 [데이터 플레인 대 제어 플레인 서비스 메시](https://medium.com/@mattklein123/service-mesh-data-plane-vs-control-plane-2774e720f7fc)에 대한 저의 포스트를 참조하시길 바랍니다.

### 다른 로드 밸런서 토폴로지 장단점 요약

- 미들 프록시 토폴로지는 일반적으로 사용하기 가장 쉬운 로드 밸런싱 토폴로지입니다. 단일 장애 지점, 스케일링 제한 및 블랙 박스 윤영으로 인해 성능이 떨어집니다.
- 엣지 프록시 토폴로지는 미들 프록시와 유사하지만 전형적으로 피해갈 수는 없습니다.
- 내장된 클라이언트 라이브러리 토폴로지는 최고의 성능과 확장성을 제공하지만 라이브러리를 모든 언어로 구현해야 하는 필요성뿐 아니라 모든 서비스에 걸쳐 라이브러리를 업그레이드해야 하는 필요성 때문에 어려움을 겪고 있습니다.
- 사이드카 프록시 토폴로지는 내장된 클라이언트 라이브러리 토폴로지와 성능이 떨어지지는 않지만 그 어떤 한계로부터 어려움을 겪지는 않습니다.

전반적으로, 저는 사이드카 프록시 토폴로지(서비스 메시)가 서비스 간의 통신을 위해 다른 모든 토폴로지를 점차 대체할 것이라고 생각합니다. 엣지 프록시 토폴로지는 항상 트래픽이 서비스 메쉬로 들어가기 전에 필요합니다.

## L4 로드 밸런싱의 기술 현황

## L7 로드 밸런싱의 기술 현황

## 하드웨어에서 소프트웨어로의 진화

## 결론 및 로드 밸런싱의 미래