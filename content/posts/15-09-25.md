+++
date          = "2015-09-25T11:01:21+09:00"
draft         = false
title         = "[번역] Effective Go: Concurrency"
tags          = [ "golang", "concurrency", "channel"]
categories    = [ "Programming"]
slug          = "effective-go-concurrency"
notoc         = true
socialsharing = true
nocomment     = false
+++

> 병행 프로그래밍은 Scala의 Actor Model이 답이라고 생각하며 Scala의 화려하고 복잡한 문법에 허우적 거리고 있던 어느 한 때, Go의 아름답고 간결한 병행 프로그래밍 문법에 매료되어 버렸다. 정신을 차리고 보니 [LearnConcurrency](https://github.com/golang/go/wiki/LearnConcurrency)의 내용을 공부하면서 필요한 대로 하나씩 정리해가고 있었다. 그 중에서 [Effective Go](https://golang.org/doc/effective_go.html#concurrency) 문서를 읽기 위해 [한글화 문서](https://code.google.com/p/golang-korea/wiki/EffectiveGo)에서 찾을 수 있었는데, Concurrency에 대한 부분이 빠져 있어서 해당 부분만 따로 번역해보았다. 다시 한번 밝히지만, 원문의 출처는 [여기](https://golang.org/doc/effective_go.html#concurrency)다.

## 통신에 의한 공유 (Share by communicating)

병행 프로그래밍 (Concurrent Programming)은 큰 주제이므로 여기에는 Go 특정적으로 강조되는 지면만 있습니다.

여러 환경에서 병행 프로그래밍은 공유 변수에 대한 정확한 억세스를 구현하는데 필요한 중요한 세부사항들로 어렵게 만들어졌습니다. Go는 공유 변수가 채널로 전달되는 다른 접근을 권장합니다. 실제로는, 분리된 스레드들의 실행에 의해 전혀 공유되지 않습니다. 언제든지 하나의 고루틴만이 값에 억세스합니다. 데이터 경쟁 (Data Race)은 구현 설계상 발생할 수 없습니다. 우리는 이 사고방식을 권장하기 위해 이를 한 슬로건으로 줄여 보았습니다.

> 공유 메모리로 통신하지 마세요. 대신, 통신으로 메모리를 공유하세요. (Do not communicate by sharing memory; instead, share memory by communicating)

이런 접근은 너무 지나친 것일 수 있습니다. 예를 들어, 정수형 변수 주위에 뮤텍스를 두는 방식의 레퍼런스 카운트 (Reference Count)가 최고일지도 모르죠. 그러나 상위 레벨에서 접근하자면, 억세스를 제어하는 채널을 사용하는 것이 분명하고 정확한 프로그램을 보다 쉽게 작성케 합니다. 

이 모델에 대해 생각하는 방법 중 하나는 하나의 CPU에서 실행되는 일반적인 단일 스레드 프로그램을 생각해보는 것입니다. 이는 동기화 기본 자료형이 필요 없습니다. 지금 또 하나의 그 인스턴스를 실행하므로 역시 동기화가 필요하지 않습니다. 이제 그 두 개를 통신하게 하는데, 통신이 동기화 장치 (synchronizer)인 경우, 여전히 다른 동기화가 필요 없습니다. 예를 들어, 유닉스 파이프 라인은 이 모델에 완벽하게 들어 맞습니다. 동시성에 대한 Go의 접근 방식이 호어의 통신 순차적 프로세스 (CSP, Communicating Sequential Processes)에서 비롯되었지만, 유닉스 파이프의 타입 세이프 일반화 (type-safe generalization)로도 볼 수 있습니다.

## 고루틴 (Goroutines)

스레드, 코루틴, 프로세스 등 기존의 용어는 부정확 함의를 전달하기 때문에 그들을 고루틴이라고 부릅니다. 고루틴은 단순한 모델을 가집니다. 고루틴은 같은 주소 공간 내에 다른 고루틴과 함께 동시에 실행되는 함수입니다. 스택 영역을 할당하는 것에 비해 거의 비용이 들지 않으므로 가볍습니다. 그리고 그 스택은 작은 규모로 시작합니다. 그래서 그들은 저렴하고, 필요에 따라 힙 스토리지를 할당(또는 해제)하여 자랍니다.

고루틴은 I/O를 위해 대기하는 동안이라든지, 실행되는 연속 작업들처럼 하나가 블락이 되면, 다중 OS 스레드에 멀티플렉싱됩니다. 이러한 설계는 스레드 생성 및 관리에 대한 여러가지 복잡성을 숨깁니다.

새로운 고루틴의 호출을 실행하기 위해 `go` 키워드를 함수 또는 메소드 호출 앞에 둡니다. 호출이 완료되면, 고루틴은 자동으로 종료됩니다. (백그라운드에서 실행되는 명령의 유닉스 쉘 및 표기법과 유사한 효과입니다.)

```
  go list.Sort()  // list.Sort를 기다리지 말고 동시에 실행
```

함수 리터럴은 고루틴 호출에 유용할 수 있습니다.

```
  func Announce(message string, delay time.Duration) {
    go func() {
        time.Sleep(delay)
        fmt.Println(message)
    }()  //괄호 주목 - 반드시 함수를 호출해야 함
  }
```

Go에서 함수 리터럴은 클로저입니다. 그러므로 함수에 의해 참조되는 변수는 반드시 그들이 액티브되는 한 오래 생존할 수 있게 구현해야 합니다.

위의 예제는 함수가 시그널링을 종료하는 방법이 없기 때문에 아주 실용적이진 않습니다.  이를 위해 채널이 필요합니다.

## 채널 (Channels)

맵과 마찬가지로, 채널은 `make`로 할당되고 , 그 결과 값은 실제 데이터 구조에 대한 참조로서 동작합니다. 선택적인 정수형 매개변수가 주어지는 경우, 채널에 대한 버퍼 크기를 설정합니다. 이 값은 언버퍼드(Unbuffered) 또는 동기 채널에 대해서 기본값이 0입니다.

```
  ci := make(chan int)            // 정수형의 언버퍼드 채널
  cj := make(chan int, 0)         // 정수형의 언버퍼드 채널
  cs := make(chan *os.File, 100)  // File 포인터형의 버퍼드 채널
```

언버퍼드 채널은 두 계산 (고루틴들) 상태를 알고 있다는 것을 보장하는 동기화로 값을 교환하는 방식의 통신을 결합합니다. 

채널을 사용하는 멋진 용법들이 많이 있습니다. 다음 한 예제로 시작해 봅시다. 이전 섹션에서 백그라운드에서 정렬을 했습니다. 채널은 정렬이 완료될 때까지 고루틴 실행을 대기시킬 수 있습니다.

```
  c := make(chan int)  // 채널 할당
  // 고루틴에서 정렬 시작. 완료되면 채널 시그널을 On시킴
  go func() {
      list.Sort()
      c <- 1  //  시그널을 보냄, 값은 문제가 안됨
  }()
  doSomethingForAWhile()
  <-c   // 정렬이 멈출 때까지 기다림, 받은 값은 버림
```

수신할 데이터가 있을 때까지 수신부는 항상 블락됩니다. 언버퍼드 채널인 경우,  송신부는 수신부가 값을 받을 때까지 블락됩니다. 버퍼드 채널인 경우, 값이 버퍼에 복사될 때까지만 송신부가 블락됩니다. 그러므로 버퍼가 가득 찼다면, 이는 어느 수신부가 값을 획득할 때까지 기다리고 있다는 것을 의미합니다.

버퍼드 채널은 세마포처럼 사용될 수 있습니다. 예를 들어 처리량을 제한하는 거죠. 이 예제에서, 들어오는 요청은 채널에 값을 전달하는  `handle`에 전달되고 요청을 처리한 후, 다음 (요청) 소비자에 대해 세마포를 준비하는 채널에서 값을 수신합니다. 

```
  var sem = make(chan int, MaxOutstanding)

  func handle(r *Request) {
      sem <- 1    // 액티브큐가 비워질 때까지 대기
      process(r)  // 다소 시간이 걸리는 작업
      <-sem       // 완료, 실행되는 다음 요청을 활성화
  }

  func Serve(queue chan *Request) {
      for {
          req := <-queue
          go handle(req)  // 완료될 때가지 대기하지 않음
      }
  }
```

일단 MaxOutstanding 핸들러가 `process`를 실행하면, 기존 핸들러 중 하나가 완료되고 버퍼로부터 값을 받을 때까지 충전된 채널 버퍼에 보내려는 그 무엇도 블락하지 않습니다.

그러나 이 설계는 문제가 있습니다. 이들 중 항상 `MaxOutstanding`만이 실행되는데도, 서버가 들어오는 모든 요청에 대해 새로운 고루틴을 생성한다는 것입니다. 그 결과, 요청이 너무 빨리 들어올 경우, 무제한으로 리소스를 소비할 수 있습니다. 이 결함은  `Serve`를 고루틴을 생성하는 게이트로 수정함으로써 다룰 수 있습니다. 확실한 솔루션은 다음과 같습니다. 하지만, 이어서 수정하게 될 버그에 주의하세요. 

```
  func Serve(queue chan *Request) {
      for req := range queue {
          sem <- 1
          go func() {
              process(req) // 버그. 아래 설명을 참조
              <-sem
          }()
      }
  }
```

버그는 Go `for` 루프 내에 있습니다. 루프 변수는 각 반복마다 재사용되는데, 따라서 동일한 `req` 변수가 모든 고루틴에 걸쳐 공유됩니다. 이는 우리가 원하는 것이 아니죠.  각 고루틴마다 구별된 `req` 변수를 가지도록 해야합니다. 다음은 이를 위한 한 가지 방법입니다. 고루틴의 클로져에 대한 인자로 `req` 값을 전달하는 거죠. 

```
  func Serve(queue chan *Request) {
      for req := range queue {
          sem <- 1
          go func(req *Request) {
              process(req)
              <-sem
          }(req)
      }
  }
```

이전 버전과 클로져가 어떻게 선언되고 실행되는지 차이점을 보기 위해 다음 버전을 비교해보세요. 또다른 솔루션은 그냥 같은 이름의 새로운 변수를 생성하는 것입니다. 예제에서 보는 것처럼요.

```
  func Serve(queue chan *Request) {
      for req := range queue {
          req := req // 고루틴에 대해 새로운 req 인스턴스를 생성
          sem <- 1
          go func() {
              process(req)
              <-sem
          }()
      }
  }
```

작성하는데 이상해 보일지도 모르겠네요.

```
  req := req
```

하지만 Go에서 이렇게 하는 것은 합법적이고 관용적인 것입니다.  똑같은 이름의 지닌 새로운 버전의 변수를 가지게 되는데, 이는 의도적으로 루프 변수를 (지역적으로) 가리게 되지만 각 고루틴에 대해서는 유니크한 값입니다.

서버를 작성하는 일반적인 문제로 돌아가자면, 리소스를 잘 관리하는 다른 방법은 요청 채널을 읽는 모든  `handle` 고루틴을 고정된 수에서 시작하는 것입니다.  고루틴의 수는 `process`가 동시에 호출되는 수를 제한합니다. 이 `Serve` 함수는 종료 신호를 수신하게 되는 채널 또한 (함수 매개변수로) 허용하고 있습니다. 고루틴이 시작되면, 이 채널로부터의 수신은 블락됩니다.

```
  func handle(queue chan *Request) {
      for r := range queue {
          process(r)
      }
  }

  func Serve(clientRequests chan *Request, quit chan bool) {
      // 핸들러 시작
      for i := 0; i < MaxOutstanding; i++ {
          go handle(clientRequests)
      }
      <-quit  // 종료 신호를 받을 때까지 대기
  }
```

## 채널의 채널 (Channels of channels)
Go의 가장 중요한 특성 중 하나는 채널이 다른 것들과 마찬가지로 할당되고 전달될 수 있는 일급값 (first-class value) 이라는 것입니다. 이 속성의 일반적인 사용은 안전한, 병렬 역다중화(parallel demultiplexing)를 구현하는 것입니다. 

이전 섹션의 예제에서, `handle` 은 요청에 대해 이상적인 핸들러였으나 우리는 처리되는 타입을 정의하지 않았습니다. 해당 타입이 회신을 하게 되는 채널을 포함하는 경우, 각 클라이언트는 응답에 대한 자신의 경로를 제공 할 수 있습니다. 다음은 `Request` 타입의 개략적인 정의입니다.

```
  type Request struct {
      args        []int
      f           func([]int) int
      resultChan  chan int
  }
```

클라이언트는 함수와 그 인자뿐만 아니라 요청 객체 안에서 응답을 수신하게 되는 채널을 제공하고 있습니다. 

```
  func sum(a []int) (s int) {
      for _, v := range a {
          s += v
      }
      return
  }

  request := &Request{[]int{3, 4, 5}, sum, make(chan int)}
  // 요청 전송
  clientRequests <- request
  // 응답 대기
  fmt.Printf("answer: %d\n", <-request.resultChan)
```

서버 측에서는 핸들러 함수만 수정됩니다.

```
  func handle(queue chan *Request) {
      for req := range queue {
          req.resultChan <- req.f(req.args)
      }
  }
```

현실성있게 만들기 위해 해야할 것들이 분명히 많긴 하지만, 이 코드는 속도 제한, 병렬, 넌블락 RPC 시스템을 위한 프레임워크이면서 뮤텍스가 보이지 않습니다.

## 병렬화 (Parallelization)

이런 아이디어의 또 다른 응용 프로그램은 여러 개의 CPU 코어를 통해 계산을 병렬 처리하는 것입니다. 계산을 독립적으로 실행할 수있는 별도의 부분으로 분해할 수 있다면, 각 부분이 완료 될 때 신호를 보내는 채널들로 병렬 처리를 할 수 있습니다.

항목들의 벡터에 대해 수행하는 비용이 많이 드는 연산이 있다고 합시다. 그리고 다음의 이상적인 예제에서와 같이 각 항목에 대한 연산의 값은 독립적입니다.

```
  type Vector []float64

  //  v[i], v[i+1]에서 v[n-1]까지 연산을 적용
  func (v Vector) DoSome(i, n int, u Vector, c chan int) {
      for ; i < n; i++ {
          v[i] += u.Op(v[i])
      }
      c <- 1    // 이 부분이 완료되면 신호함
  }
```

루프에서 독립적으로 조각들을 실행합니다. CPU당 하나의 조각을 분배합니다. 이들은 어떤 순서로도 완료될 수 있지만 순서는 문제가 되지 않습니다. 그냥 모든 고루틴를 실행 한 후 채널을 비워 완료 신호를 셉니다.

```
  const numCPU = 4 // CPU  코어수

  func (v Vector) DoAll(u Vector) {
      c := make(chan int, numCPU)  // 버퍼는 선택적이나 상식적
      for i := 0; i < numCPU; i++ {
          go v.DoSome(i*len(v)/numCPU, (i+1)*len(v)/numCPU, u, c)
      }
      // 채널을 비움
      for i := 0; i < numCPU; i++ {
          <-c    // 한 태스크가 끝날 때까지 대기
      }
      // 모두 완료
  }
```

numCPU에 대한 상수값을 생성하기보다는 런타임시에 적절한 어떤 값을 요청할 수 있습니다. `runtime.NumCPU` 함수는 장치의 하드웨어 CPU 코어의 수를 반환합니다. 그래서 아래와 같이 작성할 수 있습니다.

```
  var numCPU = runtime.NumCPU()
```

또한 Go 프로그램은 동시에 실행할 수 있는 사용자 지정 코어수 (user-specified)를 보고하는 (또는 설정하는) `runtime.GOMAXPROCS` 함수가 있습니다.  `runtime.NumCPU`의 값이 기본값이지만, 쉘 환경 변수를 설정하거나 양수의 인자로 함수를 호출하여 재정의할 수 있습니다. 0으로 호출하면 바로 값을 조회합니다. 따라서 사용자의 리소스 요청을 따르고 싶은 경우, 다음과 같이 작성해야 합니다.

```
  var numCPU = runtime.GOMAXPROCS(0)
```

컴포넌트를 개별적으로 처리함으로써 프로그램을 구조화하는 동시성과 다중 CPU에서 효율성을 위해 계산을 병렬로 처리하는 병렬성의 아이디어를 혼동하지 않도록 주의하시길 바랍니다. Go의 동시성 특징이 어떤 문제를 병렬 계산으로 쉽게 구조화할 수 있지만, Go는 병렬이 아닌 병행 언어입니다. 모든 병렬화 문제가 Go에 들어맞지는 않습니다. 이 구분에 대한 논의는 [이 블로그 포스트](https://blog.golang.org/concurrency-is-not-parallelism)에 인용된 토크를 참조하세요. 

**역자 주**: 병행 프로그래밍과 병렬 프로그래밍의 차이는 아래 그림을 참조 ([출처](http://joearms.github.io/2013/04/05/concurrent-and-parallel-programming.html))

{{< figure src="http://joearms.github.io/images/con_and_par.jpg" >}}


## 누설 버퍼 (A leaky buffer)

비병행 아이디어(non-concurrent)도 병행 프로그래밍 도구로 쉽게 표현할 수 있습니다. 다음은 RPC 패키지에서 추출한 예제입니다.클라이언트 고루틴은 어떤 소스를 루프합니다. 아마도 네트워크로부터 데이터를 수신하는 소스겠죠. 버퍼를 할당하고 해제하는 것을 방지하기 위해서는 `free list`를 유지하고, 이를 나타내기 위해 버퍼 채널을 사용합니다. 채널이 비어 있으면, 새로운 버퍼를 할당합니다. 메시지 버퍼가 준비되면, `serverChan`의 서버로 전송합니다.

```
  var freeList = make(chan *Buffer, 100)
  var serverChan = make(chan *Buffer)

  func client() {
      for {
          var b *Buffer
          // 사용할 수 있는 버퍼를 취하거나 그렇지 않다면 할당
            select {
          case b = <-freeList:
              // 하나를 취함. 아무 작업도 하지 않음 
          default:
              // 버퍼가 없음. 그래서 새 버퍼를 할당함
              b = new(Buffer)
          }
          load(b)              // 네트워크에서 다음 메세지를 읽음
          serverChan <- b      // 서버에 전송
      }
  }
```

서버 루프는각 클라이언트로부터 메시지를 수신해서 처리하고, free list에 버퍼를 반환합니다.

```
  func server() {
      for {
          b := <-serverChan    // 동작을 위해 대기 
          process(b)
          // 가능할 경우 버퍼를 재사용
          select {
          case freeList <- b:
              // free list의 버퍼. 아무 것도 하지 않음
          default:
              // free list가 꽉 참, 그냥 계속
          }
      }
  }
```

클라이언트는 `freeList`에서 버퍼를 획득하려고 시도합니다. 어떤 버퍼도 사용할 수 없는 경우, 새로운 버퍼를 할당합니다. `freeList`의 서버 전송은 리스트가 꽉차지 않을 때, 즉 가비지 콜렉터에 의해 회수되도록 버퍼가 바닥으로 떨어졌을 경우 free list에 `b`를 다시 둡니다. (`select` 구문에서 `default`  절은 다른 경우가 준비되지 않은 경우에 실행됩니다. 이는 `select`는 절대 블락되지 않는다는 것을 뜻합니다.)  위 구현은  버퍼 채널 및 가비지 컬렉터 장부에 의존하여 단지 몇 줄로 누설 버킷 무료 리스트(leaky bucket free list)을 작성하고 있습니다.


이상, 나머지는 [여기 한글화 문서](https://code.google.com/p/golang-korea/wiki/EffectiveGo)를 참조하길 바란다.
